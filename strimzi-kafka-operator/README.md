# steps

## step 0: Designating Strimzi administrators

kubectl create -f install/strimzi-admin

kubectl create clusterrolebinding strimzi-admin --clusterrole=strimzi-admin --user=user1 --user=user2

Install admin to operator strimzi CRDS for kafka configuration:

https://strimzi.io/docs/operators/latest/deploying#adding-users-the-strimzi-admin-role-str

### Role types

Controller nodes operate in the control plane to manage cluster metadata and the state of the cluster using a Raft-based consensus protocol.

- Broker nodes operate in the data plane to manage the streaming of messages, receiving and storing data in topic partitions.

- Dual-role nodes fulfill the responsibilities of controllers and brokers.

### Configuration targets:

- Dynamic controller quorums

- You can configure a deployment where Strimzi manages a single Kafka cluster in the same namespace, suitable for development or testing. Alternatively, Strimzi can manage multiple Kafka clusters across different namespaces in a production environment.

- To avoid the issues associated with installing multiple Strimzi operators in a Kubernetes cluster, the following guidelines are recommended:

Install the Strimzi operator in a separate namespace from the Kafka cluster and other Kafka components it manages, to ensure clear separation of resources and configurations.

Use a single Strimzi operator to manage all your Kafka instances within a Kubernetes cluster.

Update the Strimzi operator and the supported Kafka version as often as possible to reflect the latest features and enhancements.

By following these best practices and ensuring consistent updates for a single Strimzi operator, you can enhance the stability of managing Kafka instances in a Kubernetes cluster. This approach also enables you to make the most of Strimziâ€™s latest features and capabilities.
<!-- https://strimzi.io/docs/operators/latest/deploying#con-deploy-operator-best-practices-str -->

- create and designate strimzi oeprator admins: https://strimzi.io/docs/operators/latest/deploying#adding-users-the-strimzi-admin-role-str

Retrieving the bootstrap address:
kubectl get kafka my-cluster -o=jsonpath='{.status.listeners[?(@.name=="tls")].bootstrapServers}{"\n"}'

OPTIONAL: Kafka bridge for HTTP client/producer communication
https://strimzi.io/docs/bridge/latest/

Kafka bridge api reference:
https://strimzi.io/docs/bridge/latest/#api_reference-bridge

example config files:
https://github.com/strimzi/strimzi-kafka-operator/tree/0.46.0/examples/

## Configure CA and TLS for clients/internal components

### Internal cluster CA and clients CA

To support encryption, each Strimzi component needs its own private keys and public key certificates. All component certificates are signed by an internal CA (certificate authority) called the cluster CA.

CA (Certificate Authority) certificates are generated by the Cluster Operator to verify the identities of components and clients.

Similarly, each Kafka client application connecting to Strimzi using mTLS needs to use private keys and certificates. A second internal CA, named the clients CA, is used to sign certificates for the Kafka clients.

Both the cluster CA and clients CA have a self-signed public key certificate.

Kafka brokers are configured to trust certificates signed by either the cluster CA or clients CA. Components that clients do not need to connect to only trust certificates signed by the cluster CA. Unless TLS encryption for external listeners is disabled, client applications must trust certificates signed by the cluster CA. This is also true for client applications that perform mTLS authentication.

By default, Strimzi automatically generates and renews CA certificates issued by the cluster CA or clients CA. You can configure the management of these CA certificates using Kafka.spec.clusterCa and Kafka.spec.clientsCa properties.


TODO: READ THIS!!!
https://strimzi.io/docs/operators/latest/deploying#security-str





Connecting using SASL: (didnt manage to make it work...)
```bash
NS=strimzi-kafka




broker_address=10.66.65.10
broker_port=31820

broker_user=ifoughali
broker_password=$(kubectl get secret $broker_user -n $NS -o jsonpath='{.data.password}' | base64 -d)

# secret_name=kafka-cluster-tls-cert
secret_name=kafka-cluster-cluster-ca-cert

kubectl get secret $secret_name -n $NS -o jsonpath='{.data.ca\.crt}' | base64 -d > /tmp/ca.crt

kcat -b $broker_address:$broker_port -L \
  -X security.protocol=sasl_ssl \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=ifoughali \
  -X sasl.password=Uwig0tfWvTfFMClOhTCGV15Vyx9n8Ok0 \
  -X ssl.ca.location=/tmp/ca.crt


kcat -b $broker_address:$broker_port -L \
  -X security.protocol=sasl_ssl \
  -X sasl.mechanisms=SCRAM-SHA-512 \
  -X sasl.username=$broker_user \
  -X sasl.password=$broker_password \
  -X ssl.ca.location=/tmp/ca.crt

# if ssl needs to be ignored for quick TS
# -X enable.ssl.certificate.verification=false


```

Connecting using TLS:

```bash

NS=strimzi-kafka

broker_address=10.66.65.10
broker_port=31820

broker_user=ifoughali

# secret_name=kafka-cluster-tls-cert
secret_name=kafka-cluster-ca

# Get kafka cluster CA
certs_dir=/tmp/certs

mkdir -p $certs_dir


kubectl get secret  $secret_name -n $NS -o jsonpath='{.data.tls\.crt}' | base64 -d > ca.crt
kubectl get secret $secret_name -n $NS -o jsonpath='{.data.tls\.key}' | base64 -d > ca.key








# Get the Kafka cluster CA certificate from the Kubernetes secret
kubectl get secret $secret_name -n $NS -o jsonpath='{.data.ca\.crt}' | base64 -d > $certs_dir/ca.crt


kubectl get secret  $secret_name -n $NS -o jsonpath='{.data.ca\.p12}' | base64 -d > $certs_dir/ca.p12


kubectl get secret  $secret_name -n $NS -o jsonpath='{.data.ca\.password}' | base64 -d > $certs_dir/ca.password





# Get password into a variable
P12_PASSWORD=$(cat $certs_dir/ca.password)

# Extract private key
openssl pkcs12 -in $certs_dir/ca.p12 -nocerts -out $certs_dir/ca.key -nodes -passin pass:$P12_PASSWORD

openssl pkcs12 -in $certs_dir/ca.p12 -nocerts -out $certs_dir/ca.key -nodes -passin pass:$P12_PASSWORD


# Extract certificate
openssl pkcs12 -in $certs_dir/ca.p12 -clcerts -nokeys -out $certs_dir/ca.crt -passin pass:$P12_PASSWORD





kubectl get secret $secret_name -n $NS -o jsonpath='{.data.tls\.key}' | base64 -d > $certs_dir/tls.key

# Generate a private key for the client
openssl genpkey -algorithm RSA -out $certs_dir/$broker_user.key

# Generate a Certificate Signing Request (CSR) for the client certificate
openssl req -new -key $certs_dir/$broker_user.key -out $certs_dir/$broker_user.csr -subj "/CN=$broker_user"

# Use the CA's private key to sign the CSR and create the client certificate
openssl x509 -req -in $certs_dir/$broker_user.csr -CA $certs_dir/ca.crt -CAkey $certs_dir/tls.key -CAcreateserial -out $certs_dir/$broker_user.crt -days 3650

# validate the new signed cert:
# openssl x509 -in $certs_dir/$broker_user.crt -text -noout


kcat -b $broker_address:$broker_port -L \
  -X security.protocol=ssl \
  -X ssl.key.location=$certs_dir/$broker_user.key \
  -X ssl.certificate.location=$certs_dir/$broker_user.crt \
  -X enable.ssl.certificate.verification=false
  -X ssl.ca.location=$certs_dir/ca.crt

```


## TROUBLESHOOT

Get operator logs:

```bash
NS=strimzi-kafka
kubectl -n $NS logs -l strimzi.io/kind=cluster-operator -f
```

trigger kafka cluster rollout manually:

```bash
cluster_name=kafka-cluster
namespace=strimzi-kafka
kubectl annotate kafka $cluster_name -n $namespace strimzi.io/manual-rolling-update=true
```
