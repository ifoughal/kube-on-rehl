# CRDS examples at: https://github.com/strimzi/strimzi-kafka-operator/tree/0.46.0/examples

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: controller
  namespace: strimzi-kafka
  annotations:
    strimzi.io/next-node-ids: '[0-9]'
  labels:
    strimzi.io/cluster: kafka-cluster
spec:
  replicas: 1
  roles:
  - controller
  template:
    pod:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                - key: kafka-node-id
                  operator: In
                  values:
                    - "12"
  storage:
    type: jbod
    volumes:
    - id: 0
      type: persistent-claim
      size: 50Gi
      deleteClaim: false
      kraftMetadata: shared
      # selector:
      #   hdd-type: ssd
      # class: my-storage-class
---
#  apply this to replace dual-role later. as we do not want to expsoe the controllers...
# apiVersion: kafka.strimzi.io/v1beta2
# kind: KafkaNodePool
# metadata:
#   name: broker
#   namespace: strimzi-kafka
#   annotations:
#     strimzi.io/next-node-ids: '[10-100]'
#   labels:
#     strimzi.io/cluster: kafka-cluster
# spec:
#   replicas: 3
#   roles:
#   - broker
#   storage:
#     type: jbod
#     volumes:
#     - id: 0
#       type: persistent-claim
#       size: 100Gi
#       deleteClaim: false
#       class: rook-ceph-block
#       # selector:
#       #   hdd-type: nvme
#       # class: my-storage-class
#     - id: 1
#       type: persistent-claim
#       size: 100Gi
#       deleteClaim: false
#       class: rook-ceph-block
#     - id: 2
#       type: persistent-claim
#       size: 100Gi
#       deleteClaim: false
#       class: rook-ceph-block

apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: broker-a
  namespace: strimzi-kafka
  annotations:
    strimzi.io/next-node-ids: '[10]'
  labels:
    strimzi.io/cluster: kafka-cluster
spec:
  replicas: 1
  roles:
  - broker
  template:
    pod:
      securityContext:
        # runAsUser: 101
        # runAsGroup: 101
        # fsGroup: 0
        fsGroupChangePolicy: "OnRootMismatch"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kafka-node-id
                operator: In
                values:
                - "10"
  resources:
    requests:
      memory: 4Gi
      cpu: "4"
    limits:
      memory: 8Gi
      cpu: "8"
  storage:
    type: jbod
    volumes:
    - id: 0
      type: persistent-claim
      size: 100Gi
      deleteClaim: false
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: broker-b
  namespace: strimzi-kafka
  annotations:
    strimzi.io/next-node-ids: '[11]'
  labels:
    strimzi.io/cluster: kafka-cluster
spec:
  replicas: 1
  roles:
    - broker
  template:
    pod:
      securityContext:
        # runAsUser: 101
        # runAsGroup: 101
        # fsGroup: 0
        fsGroupChangePolicy: "OnRootMismatch"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kafka-node-id
                operator: In
                values:
                - "11"
  resources:
    requests:
      memory: 4Gi
      cpu: "4"
    limits:
      memory: 8Gi
      cpu: "8"
  storage:
    type: jbod
    volumes:
    - id: 0
      type: persistent-claim
      size: 100Gi
      deleteClaim: false

---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaNodePool
metadata:
  name: broker-c
  namespace: strimzi-kafka
  annotations:
    strimzi.io/next-node-ids: '[12]'
  labels:
    strimzi.io/cluster: kafka-cluster
spec:
  replicas: 1
  roles:
    - broker
  template:
    pod:
      securityContext:
        # runAsUser: 101
        # runAsGroup: 101
        # fsGroup: 0
        fsGroupChangePolicy: "OnRootMismatch"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kafka-node-id
                operator: In
                values:
                - "12"
  resources:
    requests:
      memory: 4Gi
      cpu: "4"
    limits:
      memory: 8Gi
      cpu: "8"
  storage:
    type: jbod
    volumes:
    - id: 0
      type: persistent-claim
      size: 100Gi
      deleteClaim: false
---
# apiVersion: kafka.strimzi.io/v1beta2
# kind: KafkaNodePool
# metadata:
#   name: dual-role
#   namespace: strimzi-kafka
#   labels:
#     strimzi.io/cluster: kafka-cluster
# spec:
#   replicas: 3
#   roles:
#   - controller
#   - broker
#   # REF: https://strimzi.io/docs/operators/latest/deploying#assembly-storage-str
#   storage:
#     type: jbod
#     volumes:
#     - id: 0
#       type: persistent-claim
#       size: 100Gi
#       deleteClaim: false
#       kraftMetadata: shared

apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: kafka-cluster
  namespace: strimzi-kafka
  annotations:
    strimzi.io/node-pools: enabled
    strimzi.io/kraft: enabled
spec:

  kafka:
    authorization:
      type: simple
    version: 4.0.0
    metadataVersion: 4.0-IV3
    # config:
    #   offsets.topic.replication.factor: 3
    #   transaction.state.log.replication.factor: 3
    #   transaction.state.log.min.isr: 2
    #   default.replication.factor: 3
    #   min.insync.replicas: 2
    # REF: https://strimzi.io/docs/operators/latest/configuring#property-listener-config-preferredNodePortAddressType-reference
    listeners:
    - name: plain
      port: 9092
      type: internal
      tls: false
      configuration:
        useServiceDnsDomain: true
    # - name: tls
    #   port: 9093
    #   type: internal
    #   tls: true
    #   configuration:
    #     useServiceDnsDomain: true
    #   authentication:
    #     type: tls
    - name: saslplain
      port: 9094
      # type: cluster-
      # type: loadbalancer
      type: nodeport  # this works!
      tls: false
      configuration:
        createBootstrapService: true
        # since we don't have any available IP address, we use the nodePort or CusterIP
        # loadBalancerSourceRanges:
        # - 10.66.65.10/32
        # - 10.66.65.11/32
        # - 10.66.65.12/32
        # useServiceDnsDomain: true # internal or cluster-ip only
        # brokers:
        # - broker: 10
        #   advertisedHost: kafka-broker-0.pfs.pack
        #   advertisedPort: 9094
        #   # loadBalancerIP: 10.66.65.10
        # - broker: 11
        #   advertisedHost: kafka-broker-1.pfs.pack
        #   advertisedPort: 9094
        #   # loadBalancerIP: 10.66.65.11
        # - broker: 12
        #   advertisedHost: kafka-broker-2.pfs.pack
        #   advertisedPort: 9094
        #   # loadBalancerIP: 10.66.65.12
        # bootstrap:
        #   alternativeNames:
        #   - kafka-bootstrap.pfs.pack
          # loadBalancerIP: 10.66.65.10

    - name: sasltls
      port: 9095
      # type: cluster-ip
      type: nodeport
      tls: true
      authentication:
        type: scram-sha-512
      configuration:
        brokerCertChainAndKey:
          certificate: tls.crt
          key: tls.key
          secretName: kafka-cluster-tls-cert
        brokers:
        - broker: 10
          advertisedHost: kafka-broker-0.pfs.pack
          advertisedPort: 9095
        - broker: 11
          advertisedHost: kafka-broker-1.pfs.pack
          advertisedPort: 9095
        - broker: 12
          advertisedHost: kafka-broker-2.pfs.pack
          advertisedPort: 9095
        bootstrap:
          alternativeNames:
          - kafka-bootstrap.pfs.pack
        createBootstrapService: true

  entityOperator:
    # We'll create a kafka topic and user so we need these operators.
    topicOperator:
      resources:
        requests:
          memory: 512Mi
          cpu: "1"
        limits:
          memory: 512Mi
          cpu: "1"
    userOperator:
      resources:
        requests:
          memory: 512Mi
          cpu: "1"
        limits:
          memory: 512Mi
          cpu: "1"
    # INGRESS WILL NOT WORK AS WE USE GATEWAY API!
    # - name: external2
    #   port: 9095
    #   type: ingress
    #   tls: true
    #   # authentication:
    #   #   type: tls
    #   configuration:
    #     bootstrap:
    #       # nodePort: 32100
    #       host: kafka-boostrap.pfs.pack
    #     brokers:
    #     - broker: 0
    #       # nodePort: 32000
    #       host: kafka-broker-0.pfs.pack
    #     - broker: 1
    #       # nodePort: 32001
    #       host: kafka-broker-1.pfs.pack
    #     - broker: 2
    #       # nodePort: 32001
    #       host: kafka-broker-2.pfs.pack


    # - name: external2
    #   port: 9096
    #   type: loadbalancer
    #   tls: true
    #   configuration:
    #     # loadBalancerSourceRanges:
    #     # - 10.66.65.12/32
    #     # - 10.66.65.11/32
    #     # - 10.66.65.10/32
    #     bootstrap:
    #       loadBalancerIP: 10.66.65.12
    #     brokers:
    #     - broker: 0
    #       loadBalancerIP: 10.66.65.11
    #     - broker: 1
    #       loadBalancerIP: 10.66.65.10


    # - name: external
    #   port: 9094
    #   type: cluster-ip
    #   tls: false


# status:
#   clusterId: myvE0PyuRhmQIwbhmcZXew
  # niD_eXqZRAuCAwAwhxbaxQ
  # p3LshGcWRkiT1fSRI5S6Jw





# ---

# apiVersion: kafka.strimzi.io/v1beta2
# kind: KafkaBridge
# metadata:
#   name: kafka-bridge
#   namespace: strimzi-kafka
# spec:
#   replicas: 1
#   bootstrapServers: kafka-cluster-kafka-external1-bootstrap.strimzi-kafka.svc:9094
#   http:
#     port: 8080

# # FORCE RECONCILE CHANGES AFTER APPLYING THIS CRS:
# # kubectl patch kafka kafka-cluster --type=merge -p '{"metadata":{"annotations":{"reconcile":"now"}}}'
# # CHECK STATUS:
# # kubectl get kafka kafka-cluster -o yaml
